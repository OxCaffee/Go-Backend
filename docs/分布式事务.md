# 分布式事务

## 一、CAP理论

CAP理论可以说是分布式系统的基石，它说的是**一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项**，而不能同时满足。

- **C：一致性**，所有客户端看到都是同一份数据，即使在数据更新和删除之后
- **A：可用性**，即使部分节点发生故障，所有客户端也能找到可用的数据备份
- **P：分区容忍性**，即使发生网络分区故障，系统仍然能够按照预期正常工作

## 二、BASE理论

根据CAP定理，如果要完整的实现事务的ACID特性，只能放弃可用性选择一致性，即CP模型。然而如今大多数的互联网应用中，可用性也同样至关重要。于是eBay架构师根据CAP定理进行妥协提出一种ACID替代性方案，即BASE，从而来达到可用性和一致性之间的某种微妙的平衡，选择AP模型的同时最大限度的满足一致性。

BASE具体解释如下：

- **BA**：**Basically Available** ，基本可用性：是相对CAP的“完全可用”而言的，即在部分节点出现故障的时候不要求整个系统完全可用，允许系统出现部分功能和性能上的损失：比如增加响应时间，引导用户到一个降级提示页面等等。
- **S：Soft State**，软状态：是相对CAP定理强一致性的“硬状态”而言，CAP定理的一致性要求数据变化要立即反映到所有的节点副本上去，是一种强一致性。“软状态”不要求数据变化立即反映到所有的服务器节点上，允许存在一个中间状态进行过渡，比如允许放大延时等。
- **E：Eventually Consistency**，最终一致性：是对 CAP 中一致性和可用性权衡的结果，其来源于对大型互联网分布式实践的总结，是基于 CAP 定理逐步演化而来的。其核心思想是：**强一致性（Strong consistency）无法得到保障时，我们可以根据业务自身的特点，采用适当的方式来达到最终一致性（Eventual consistency）**

## 三、基于CAP的强一致性方案

### 2PC-二阶段提交

当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。

两阶段提交也可被描述为以下：

1. **投票阶段(Voting Phase)** ：事务协调者给每个参与者发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。
2. **提交阶段(Commit Phase)** ：如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)

2PC必须包含如下假设：

- 必须假设**网络在提交阶段的短时间内是可靠的**，即提交阶段不会丢失消息。两段式提交中投票阶段失败了可以补救（回滚），而提交阶段失败了无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险的考虑。
- 必须假设因为网络分区、机器崩溃或者其他原因而导致失联的**节点最终能够恢复**，不会永久性地处于失联状态。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，并向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。

2PC缺点如下：

* 协调者宕机会造成整个事务阻塞
* 当**网络稳定性**和**宕机恢复能力**的假设不成立时，两阶段提交可能会出现一致性问题。
* 当协调者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。也就是说从投票阶段到提交阶段完成这段时间，资源是被锁住的。

### 3PC-三阶段提交

**“三段式提交”（3 Phase Commit，3PC）**协议是为了解决两段式提交的单点故障问题、同步阻塞问题和数据一致性问题。3PC相较于3PC做出了如下改进：

- **引入超时机制**: 同时在协调者和参与者中都引入超时机制。
- **把原本的2PC的准备阶段再细分为两个阶段**: 将准备阶段一分为二的理由是，这个阶段是重负载的操作，一旦协调者发出开始准备的消息，每个参与者都将马上开始写重做日志，这时候涉及的数据资源都会被锁住。如果此时某一个参与者无法完成提交，相当于所有的参与者都做了一轮无用功。所以，增加一轮询问阶段，如果都得到了正面的响应，那事务能够成功提交的把握就比较大了，也意味着因某个参与者提交时发生崩溃而导致全部回滚的风险相对变小了。

3PC过程如下：

* **CanCommit阶段** ：3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。
* **PreCommit阶段** ：本阶段协调者会根据第一阶段的询盘结果采取相应操作，询盘结果主要有两种：
  - 情况1-假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行：
  - 情况2-假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。
* **DoCommit阶段** ：该阶段进行真正的事务提交，也可以分为以下两种情况。
  - 情况1-执行提交:针对第一种情况，协调者向各个参与者发起事务提交请求
  - 情况2-中断事务:协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。

**3PC可以解决单点故障问题，并减少阻塞**，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit，而不会一直持有事务资源并处于阻塞状态。

但是**3PC对于数据一致性问题并未有任何改进**，比如在进入PreCommit阶段后，如果协调者发送的是abort指令，而此时由于网络问题，有部分参与者在等待超时后仍未收到Abort指令的话，那这些参与者就会执行commit，这样就产生了不同参与者之间数据不一致的问题。

**由于3PC非常难实现，目前市面上主流的分布式事务解决方案都是2PC协议**。

## 四、基于BASE的最终一致性

### TCC

采用2PC的解决方案，事务提交之前，其它的操作将会处于阻塞等待的状态，这会大大的降低系统的性能和用户体验。

如果业务需要隔离，通常就应该重点考虑 TCC（Try-Confirm-Cancel）方案，**TCC天生适用于需要强隔离性的分布式事务**中，它是由数据库专家帕特 · 赫兰德（Pat Helland）在 2007 年撰写的论文《Life beyond Distributed Transactions: An Apostate’s Opinion》中提出的。

在具体实现上，TCC 的操作其实有点儿麻烦和复杂，它是一种业务侵入性较强的事务方案，要求业务处理过程必须拆分为“预留业务资源”和“确认 / 释放消费资源”两个子过程。另外，你看名字也能看出来，TCC 的实现过程分为了三个阶段：

- **Try：尝试执行阶段，**完成所有业务可执行性的检查（保障一致性），并且预留好事务需要用到的所有业务资源（保障隔离性）。
- **Confirm：确认执行阶段**，不进行任何业务检查，直接使用 Try 阶段准备的资源来完成业务处理。注意，Confirm 阶段可能会重复执行，因此需要满足幂等性。
- **Cancel：取消执行阶段**，释放 Try 阶段预留的业务资源。注意，Cancel 阶段也可能会重复执行，因此也需要满足幂等性。

TCC是基于BASE理论的类2PC方案，根据业务的特性对2PC的流程进行了优化，与2PC的区别在一些步骤的细节上，如下图：

<div align=center><img src="/assets/tcc.png"/></div>

可以看出，不同于2PC第一阶段的Prepare，**TCC在Try阶段主要是对资源的预留操作这类的轻量级操作**，比如冻结部分库存数量，它不需要像2PC在第二阶段完成之后才释放整个资源，也就是它不需要等待整个事务完成后才进行提交，这时其它用户的购买操作可以继续正常进行，因此它的**阻塞范围小时间短暂，性能上比2PC方案要有很大的提升**。

另外，**TCC是位于用户代码层面**，而不是在基础设施层面，这为它的实现带来了较高的灵活性，**可以根据需要设计资源锁定的粒度**。TCC 在业务执行时只操作预留资源，**几乎不会涉及锁和资源的争用，具有很高的性能潜力。**

但是 TCC要求所有的事务参与方都必须要提供三个操作接口：Try/Confirm/Cancel，**带来了更高的开发成本和业务侵入性，意味着有更高的开发成本和更换事务实现方案的替换成本**，特别是对一些难以改动的老旧系统来说甚至是不可行的。

### SAGA

1987 年普林斯顿大学的赫克托 · 加西亚 · 莫利纳（Hector Garcia Molina）和肯尼斯 · 麦克米伦（Kenneth Salem）在 ACM 发表的一篇论文《SAGAS》。文中提出了一种如何提升“长时间事务”（Long Lived Transaction）运作效率的方法，大致思路是把一个大事务分解为可以交错运行的一系列子事务的集合。**原本提出 SAGA 的目的，是为了避免大事务长时间锁定数据库的资源，后来才逐渐发展成将一个分布式环境中的大事务，分解为一系列本地事务的设计模式**。SAGA事务模型大致如下：

- 每个 Saga 事务由一系列幂等的有序子事务(sub-transaction) 组成。
- 每个事务都有对应的幂等补偿动作，补偿动作用于撤销子事务造成的结果。

如果所有事务都成功提交，那么事务就可以顺利完成。否则，就要采取恢复策略，恢复策略分为向前恢复和向后恢复两种。

* **向前恢复** ：如果子事务提交失败，则一直对子事务进行重试，直至成功为止（最大努力交付）。这种恢复方式不需要补偿。
* **向后恢复** ：如果子事务提交失败，则一直对子事务进行补偿，直至成功为止（最大努力交付）。这里要求补偿操作必须（在持续重试后）执行成功。

SAGA的实现主要有两种模式：

* **命令协调模式** ：该模式需要全局的协调器，去集中处理事件和业务逻辑执行，**以命令和回复的方式对每个服务进行通信** 。
* **事件编排模式** ：这种模式没有中央协调器（没有单点风险），由每个服务产生并观察其他服务的事件，并决定是否应采取行动。在事件编排方法中，第一个服务执行一个事务，然后发布一个事件。该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件。当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何 Saga 参与者听到都意味着事务结束。

SAGA的适用场景：

- 业务流程长、业务流程多
- 参与者包含第三方或遗留系统服务，无法提供TCC模式要求的三个接口
- 典型业务系统：如金融网络（与外部金融机构对接）、互联网微贷、渠道整合、分布式架构服务集成等业务系统
- 银行业金融机构使用广泛

SAGA的优势在于：

- 一阶段提交本地数据库事务，无锁，高性能；
- 参与者可以采用事务驱动异步执行，高吞吐；
- 补偿服务即正向服务的“反向”，易于理解，易于实现；

SAGA的缺点在于：

* 一阶段已经提交本地数据库事务，且没有进行“预留”动作，所以**不能保证隔离性**。

## 五、总结

- **2PC/3PC**：依赖于数据库，能够很好的提供强一致性和强事务性，但相对来说延迟比较高，比较适合传统的单体应用，不适合高并发和高性能要求的场景。
- **XA协议**：基于XA协议的强一致事务使用起来相对简单，但是无法很好地应对互联网的短事务和高并发场景。
- **本地事务状态表**：方案轻量，容易实现，但与具体的业务场景耦合较高，不可公用。
- **可靠消息队列**：适合执行周期长且实时性要求不高的场景。引入消息机制后，同步的事务操作变为基于消息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦。典型的使用场景：注册送积分，登录送优惠券等。
- **最大努力通知**：是分布式事务中要求最低的一种,适用于一些最终一致性时间敏感度低的业务；允许发起通知方处理业务失败，在接收通知方收到通知后积极进行失败处理，无论发起通知方如何处理结果都会不影响到接收通知方的后续处理；发起通知方需提供查询执行情况接口，用于接收通知方校对结果。典型的使用场景：银行通知、支付结果通知等。
- **TCC**：适用于执行时间确定且较短，实时性要求高，对数据一致性要求高，比如互联网金融企业最核心的三个服务：交易、支付、账务。但是对于业务的侵入性非常强，业务逻辑的每个分支都需要实现try、confirm、cancel三个操作。此外，其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。
- **SAGA**：适合于“业务流程长、业务流程多”的场景。特别是针对参与事务的服务是遗留系统服务。但由于 Saga 事务不能保证隔离性，需要在业务层控制并发，适合于业务场景事务并发操作同一资源较少的情况。另外， Saga 相比缺少预提交动作，导致补偿动作的实现比较麻烦，例如业务是发送短信，补偿动作则得再发送一次短信说明撤销，用户体验比较差。Saga 事务较适用于补偿动作容易处理的场景。
- **弱一致性方案**：上面给出的几种弱一致性方案是在高并发等场景下，为了提高系统的性能和可用性而在一致性方面做的妥协，一般需要结合具体的业务特点、实现成本等各方因素对一些最终一致性方案做改造。